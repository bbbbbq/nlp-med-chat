#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤§è§„æ¨¡åŒ»ç–—çŸ¥è¯†æ•°æ®å¤„ç†è„šæœ¬
å°†ä¸‹è½½çš„åŒ»ç–—çŸ¥è¯†å›¾è°±æ•°æ®è½¬æ¢ä¸ºRAGç³»ç»Ÿå¯ç”¨çš„æ ¼å¼
"""

import json
import re
from typing import List, Dict, Any

def clean_text(text: str) -> str:
    """æ¸…ç†æ–‡æœ¬ï¼Œå»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦å’Œç‰¹æ®Šç¬¦å·"""
    if not isinstance(text, str):
        return str(text)
    
    # å»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    text = re.sub(r'\s+', ' ', text.strip())
    # å»é™¤ä¸€äº›ç‰¹æ®Šç¬¦å·
    text = re.sub(r'[^\w\s\u4e00-\u9fffï¼Œã€‚ï¼›ï¼šï¼ï¼Ÿã€ï¼ˆï¼‰ã€ã€‘ã€Šã€‹""''ï¼…%]', '', text)
    return text

def extract_symptoms_from_text(desc: str, symptom_list: List[str]) -> List[str]:
    """ä»æè¿°æ–‡æœ¬ä¸­æå–ç—‡çŠ¶å…³é”®è¯"""
    symptoms = set()
    
    # æ·»åŠ æ˜ç¡®çš„ç—‡çŠ¶åˆ—è¡¨
    if symptom_list:
        symptoms.update(symptom_list)
    
    # ä»æè¿°ä¸­æå–å¸¸è§ç—‡çŠ¶å…³é”®è¯
    symptom_keywords = [
        'ç–¼ç—›', 'å‘çƒ­', 'å’³å—½', 'å‘¼å¸å›°éš¾', 'èƒ¸ç—›', 'å¤´ç—›', 'æ¶å¿ƒ', 'å‘•å', 
        'è…¹ç—›', 'è…¹æ³»', 'ä¾¿ç§˜', 'ä¹åŠ›', 'å¤´æ™•', 'å¤±çœ ', 'é£Ÿæ¬²ä¸æŒ¯', 'ä½“é‡ä¸‹é™',
        'çš®ç–¹', 'ç˜™ç—’', 'æ°´è‚¿', 'å‡ºè¡€', 'ç´«ç»€', 'é»„ç–¸', 'è´«è¡€', 'å¿ƒæ‚¸',
        'æ°”çŸ­', 'èƒ¸é—·', 'å’¯è¡€', 'ç›—æ±—', 'å¯’æˆ˜', 'å…³èŠ‚ç—›', 'è‚Œè‚‰ç—›', 'éº»æœ¨'
    ]
    
    for keyword in symptom_keywords:
        if keyword in desc:
            symptoms.add(keyword)
    
    return list(symptoms)

def categorize_disease(category_list: List[str], name: str) -> str:
    """æ ¹æ®åˆ†ç±»ä¿¡æ¯ç¡®å®šç–¾ç—…ç±»åˆ«"""
    if not category_list:
        return "å…¶ä»–ç–¾ç—…"
    
    # å®šä¹‰åˆ†ç±»æ˜ å°„
    category_mapping = {
        'å‘¼å¸å†…ç§‘': 'å‘¼å¸ç³»ç»Ÿç–¾ç—…',
        'å¿ƒè¡€ç®¡å†…ç§‘': 'å¿ƒè¡€ç®¡ç–¾ç—…', 
        'æ¶ˆåŒ–å†…ç§‘': 'æ¶ˆåŒ–ç³»ç»Ÿç–¾ç—…',
        'ç¥ç»å†…ç§‘': 'ç¥ç»ç³»ç»Ÿç–¾ç—…',
        'å†…åˆ†æ³Œç§‘': 'å†…åˆ†æ³Œç–¾ç—…',
        'æ³Œå°¿å¤–ç§‘': 'æ³Œå°¿ç³»ç»Ÿç–¾ç—…',
        'éª¨ç§‘': 'éª¨ç§‘ç–¾ç—…',
        'å¤–ç§‘': 'å¤–ç§‘ç–¾ç—…',
        'å¦‡äº§ç§‘': 'å¦‡ç§‘ç–¾ç—…',
        'çš®è‚¤ç§‘': 'çš®è‚¤ç–¾ç—…',
        'çœ¼ç§‘': 'çœ¼ç§‘ç–¾ç—…',
        'è€³é¼»å–‰ç§‘': 'è€³é¼»å–‰ç–¾ç—…',
        'ç²¾ç¥ç§‘': 'ç²¾ç¥ç–¾ç—…',
        'å„¿ç§‘': 'å„¿ç§‘ç–¾ç—…'
    }
    
    # æ£€æŸ¥åˆ†ç±»åˆ—è¡¨ä¸­çš„ç§‘å®¤
    for cat in category_list:
        for dept, disease_type in category_mapping.items():
            if dept in cat:
                return disease_type
    
    # æ ¹æ®ç–¾ç—…åç§°æ¨æ–­åˆ†ç±»
    if any(keyword in name for keyword in ['è‚º', 'å‘¼å¸', 'å’³å—½', 'æ°”ç®¡', 'æ”¯æ°”ç®¡']):
        return 'å‘¼å¸ç³»ç»Ÿç–¾ç—…'
    elif any(keyword in name for keyword in ['å¿ƒ', 'è¡€ç®¡', 'åŠ¨è„‰', 'é™è„‰']):
        return 'å¿ƒè¡€ç®¡ç–¾ç—…'
    elif any(keyword in name for keyword in ['èƒƒ', 'è‚ ', 'è‚', 'èƒ†', 'èƒ°', 'æ¶ˆåŒ–']):
        return 'æ¶ˆåŒ–ç³»ç»Ÿç–¾ç—…'
    elif any(keyword in name for keyword in ['è„‘', 'ç¥ç»', 'å¤´ç—›', 'ç™«ç—«']):
        return 'ç¥ç»ç³»ç»Ÿç–¾ç—…'
    elif any(keyword in name for keyword in ['ç³–å°¿ç—…', 'ç”²çŠ¶è…º', 'å†…åˆ†æ³Œ']):
        return 'å†…åˆ†æ³Œç–¾ç—…'
    elif any(keyword in name for keyword in ['è‚¾', 'è†€èƒ±', 'å°¿', 'æ³Œå°¿']):
        return 'æ³Œå°¿ç³»ç»Ÿç–¾ç—…'
    elif any(keyword in name for keyword in ['éª¨', 'å…³èŠ‚', 'è‚Œè‚‰', 'éŸ§å¸¦']):
        return 'éª¨ç§‘ç–¾ç—…'
    elif any(keyword in name for keyword in ['çš®è‚¤', 'æ¹¿ç–¹', 'çš®ç‚']):
        return 'çš®è‚¤ç–¾ç—…'
    else:
        return 'å…¶ä»–ç–¾ç—…'

def process_medical_data(input_file: str, output_file: str, max_records: int = None):
    """å¤„ç†åŒ»ç–—æ•°æ®å¹¶è½¬æ¢ä¸ºRAGç³»ç»Ÿæ ¼å¼"""
    processed_data = []
    
    print(f"ğŸ”„ å¼€å§‹å¤„ç†åŒ»ç–—çŸ¥è¯†æ•°æ®...")
    
    with open(input_file, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f):
            if max_records and len(processed_data) >= max_records:
                break
                
            if line.strip():
                try:
                    data = json.loads(line.strip())
                    
                    # æå–åŸºæœ¬ä¿¡æ¯
                    name = data.get('name', '').strip()
                    desc = data.get('desc', '').strip()
                    category_list = data.get('category', [])
                    symptom_list = data.get('symptom', [])
                    cause = data.get('cause', '').strip()
                    prevent = data.get('prevent', '').strip()
                    cure_way = data.get('cure_way', [])
                    check_methods = data.get('check', [])
                    
                    if not name or not desc:
                        continue
                    
                    # æ¸…ç†å’Œå¤„ç†æ•°æ®
                    name = clean_text(name)
                    desc = clean_text(desc)
                    cause = clean_text(cause)
                    prevent = clean_text(prevent)
                    
                    # æå–ç—‡çŠ¶
                    symptoms = extract_symptoms_from_text(desc + ' ' + cause, symptom_list)
                    
                    # ç¡®å®šç–¾ç—…åˆ†ç±»
                    disease_category = categorize_disease(category_list, name)
                    
                    # æ„å»ºRAGæ ¼å¼çš„æ•°æ®
                    rag_entry = {
                        'disease': name,
                        'category': disease_category,
                        'description': desc,
                        'symptoms': symptoms[:10],  # é™åˆ¶ç—‡çŠ¶æ•°é‡
                        'causes': cause if cause else 'ç—…å› ä¸æ˜',
                        'prevention': prevent if prevent else 'æš‚æ— é¢„é˜²æªæ–½',
                        'treatment': cure_way[:5] if cure_way else ['å¯¹ç—‡æ²»ç–—'],
                        'diagnosis_methods': check_methods[:5] if check_methods else ['ä¸´åºŠè¯Šæ–­'],
                        'severity': 'ä¸­ç­‰',  # é»˜è®¤ä¸¥é‡ç¨‹åº¦
                        'imaging_findings': ['éœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥']  # é»˜è®¤å½±åƒå­¦è¡¨ç°
                    }
                    
                    processed_data.append(rag_entry)
                    
                    if len(processed_data) % 1000 == 0:
                        print(f"âœ… å·²å¤„ç† {len(processed_data)} æ¡è®°å½•...")
                        
                except json.JSONDecodeError as e:
                    print(f"âš ï¸  ç¬¬{line_num+1}è¡ŒJSONè§£æé”™è¯¯: {e}")
                    continue
                except Exception as e:
                    print(f"âš ï¸  ç¬¬{line_num+1}è¡Œå¤„ç†é”™è¯¯: {e}")
                    continue
    
    print(f"ğŸ‰ æ•°æ®å¤„ç†å®Œæˆï¼æ€»å…±å¤„ç†äº† {len(processed_data)} æ¡è®°å½•")
    
    # ç»Ÿè®¡åˆ†ç±»ä¿¡æ¯
    category_stats = {}
    for entry in processed_data:
        cat = entry['category']
        category_stats[cat] = category_stats.get(cat, 0) + 1
    
    print(f"ğŸ“Š ç–¾ç—…åˆ†ç±»ç»Ÿè®¡:")
    for cat, count in sorted(category_stats.items(), key=lambda x: x[1], reverse=True):
        print(f"  {cat}: {count} æ¡")
    
    # ä¿å­˜å¤„ç†åçš„æ•°æ®
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("#!/usr/bin/env python3\n")
        f.write("# -*- coding: utf-8 -*-\n")
        f.write('"""\n')
        f.write("å¤§è§„æ¨¡åŒ»å­¦çŸ¥è¯†åº“æ•°æ®\n")
        f.write(f"åŒ…å« {len(processed_data)} æ¡åŒ»å­¦çŸ¥è¯†æ¡ç›®\n")
        f.write('"""\n\n')
        f.write("LARGE_MEDICAL_KNOWLEDGE_DATABASE = ")
        f.write(json.dumps(processed_data, ensure_ascii=False, indent=2))
        f.write("\n\n")
        f.write("def get_large_medical_knowledge_count():\n")
        f.write(f'    """è·å–å¤§è§„æ¨¡åŒ»å­¦çŸ¥è¯†æ¡ç›®æ•°é‡"""\n')
        f.write(f"    return {len(processed_data)}\n\n")
        f.write("def get_large_medical_knowledge_by_category(category):\n")
        f.write('    """æ ¹æ®åˆ†ç±»è·å–å¤§è§„æ¨¡åŒ»å­¦çŸ¥è¯†"""\n')
        f.write("    return [item for item in LARGE_MEDICAL_KNOWLEDGE_DATABASE if item['category'] == category]\n\n")
        f.write("def get_all_large_categories():\n")
        f.write('    """è·å–æ‰€æœ‰å¤§è§„æ¨¡ç–¾ç—…åˆ†ç±»"""\n')
        f.write("    return list(set(item['category'] for item in LARGE_MEDICAL_KNOWLEDGE_DATABASE))\n")
    
    print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
    return len(processed_data)

if __name__ == "__main__":
    # å¤„ç†æ•°æ®ï¼Œé™åˆ¶ä¸ºå‰2000æ¡ä»¥é¿å…æ–‡ä»¶è¿‡å¤§
    count = process_medical_data(
        input_file="data/medical.json",
        output_file="data/large_medical_knowledge_data.py",
        max_records=2000
    )
    print(f"ğŸš€ å¤§è§„æ¨¡åŒ»ç–—çŸ¥è¯†åº“å‡†å¤‡å®Œæˆï¼åŒ…å« {count} æ¡è®°å½•")
